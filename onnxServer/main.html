<!DOCTYPE html>
<html>
  <header>
    <title>
      ONNX Runtime JavaScript examples: Quick Start - Web (using script tag)
    </title>
  </header>
  <body>
    <!-- import ONNXRuntime Web from CDN -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script> -->
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/onnxruntime-web/1.14.0-dev.20221124-4ca62b9ee8/ort.min.js"
      integrity="sha512-PANEkbiBMZ0EIRMtKm2M/NEtV2TbwXHhltLpqiNO57tpCeX0cseuaXKTdlAWFXsDxGwhX9AcHVYhLT/GEHfDBg=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>
    <script>
      // use an async context to call onnxruntime functions.
      async function main() {
        const decoder = (i) => {
          return fetch("/", { body: JSON.stringify(i), method: "PUT" });
        };

        console.log(await (await decoder([0])).text());

        const encoder = (i) => {
          return fetch("/", { body: JSON.stringify(i), method: "POST" });
        };
        // create a new session and load the specific model.
        //
        // the model in this example contains a single MatMul node
        // it has 2 inputs: 'a'(float32, 3x4) and 'b'(float32, 4x3)
        // it has 1 output: 'c'(float32, 3x3)
        // const sessionOption = { executionProviders: ["webgl"] };
        const encoding = await encoder("hello");

        jencoding = await encoding.json();

        console.log(jencoding);

        const tensorA = new ort.Tensor("float32", jencoding[0], [
          jencoding[0].length,
        ]);

        const session = await ort.InferenceSession.create(
          "layer0.onnx",
          { executionProviders: ["webgl"] }
          // sessionOption, cant get opengl rendering
        );

        const postProcess = await ort.InferenceSession.create(
          "postprocess.onnx",
          { executionProviders: ["webgl"] }
          // // sessionOption, cant get opengl rendering
        );

        const preProcess = await ort.InferenceSession.create(
          "preprocess.onnx"
          // { executionProviders: ["webgl"] }
          // // sessionOption, cant get opengl rendering
        );

        // prepare inputs. a tensor need its corresponding TypedArray as data

        const empty_state = () => {
          const dataB = new Float32Array(4 * 12 * 768);
          // for i in range(layers):
          //     state[5*i+4] -= 1e30
          for (let i = 0; i < dataB.length; i++) {
            dataB[i] = 0;
          }

          return new ort.Tensor("float32", dataB, [4, 12, 768]);
        };

        const tensorB = empty_state();

        // prepare feeds. use model input names as keys.

        const output = [];
        var feeds = { "probs.1": tensorA, "outstate.1": tensorB };
        console.log(feeds);
        // feed inputs and run
        for (let i = 0; i < 100; i++) {
          const resultA = await session.run(feeds);

          console.log(resultA);

          const result = await postProcess.run({
            "probs.1": resultA.probs,
            "outstate.1": tensorB,
          });

          console.log(result);

          const outdata = new Int32Array(1);
          // Greedy decoding
          outdata[0] = result["probs"].data.reduce(
            (a, b, c) => (b > a[0] ? [b, c] : a),
            [0, 0]
          )[1];

          output.push(outdata[0]);
          const pr = {};
          const tensorA = new ort.Tensor("int32", outdata, [1]);
          pr["probs.1"] = tensorA;
          pr["outstate.1"] = result["outstate"];

          feeds["probs.1"] = (await preProcess.run(pr))["probs"];
          feeds["outstate.1"] = tensorB;
        }

        // read from results
        res = await (await decoder(output)).text();
        document.getElementById("bodyit").innerHTML = res;
        console.log(res);
      }

      main();
    </script>
    <div id="bodyit">Body</div>
  </body>
</html>
